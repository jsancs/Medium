{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} images in the dataset'.format(len(glob.glob('images/*.jpg'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATS = ['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair', 'Egyptian_Mau', 'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue', 'Siamese', 'Sphynx']\n",
    "\n",
    "cats_images = []\n",
    "dogs_images = []\n",
    "\n",
    "for img in glob.glob('images/*.jpg'):\n",
    "    if any(cat in img for cat in CATS):\n",
    "        cats_images.append(img)\n",
    "    else:\n",
    "        dogs_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} images of cats'.format(len(cats_images)))\n",
    "print('There are {} images of dogs'.format(len(dogs_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the lists\n",
    "np.random.shuffle(cats_images)\n",
    "np.random.shuffle(dogs_images)\n",
    "\n",
    "#split the data into train, validation and test sets\n",
    "train_d, val_d, test_d = np.split(dogs_images, [int(len(dogs_images)*0.7), int(len(dogs_images)*0.8)])\n",
    "train_c, val_c, test_c = np.split(cats_images, [int(len(cats_images)*0.7), int(len(cats_images)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dog_df = pd.DataFrame({'image':train_d, 'label':'dog'})\n",
    "val_dog_df = pd.DataFrame({'image':val_d, 'label':'dog'})\n",
    "test_dog_df = pd.DataFrame({'image':test_d, 'label':'dog'})\n",
    "\n",
    "train_cat_df = pd.DataFrame({'image':train_c, 'label':'cat'})\n",
    "val_cat_df = pd.DataFrame({'image':val_c, 'label':'cat'})\n",
    "test_cat_df = pd.DataFrame({'image':test_c, 'label':'cat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_dog_df, train_cat_df])\n",
    "val_df = pd.concat([val_dog_df, val_cat_df])\n",
    "test_df = pd.concat([test_dog_df, test_cat_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} images for training'.format(len(train_df)))\n",
    "print('There are {} images for validation'.format(len(val_df)))\n",
    "print('There are {} images for testing'.format(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale the images\n",
    "trainGenerator = ImageDataGenerator(rescale=1./255.)\n",
    "valGenerator = ImageDataGenerator(rescale=1./255.)\n",
    "testGenerator = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "#convert them into a dataset\n",
    "trainDataset = trainGenerator.flow_from_dataframe(\n",
    "  dataframe=train_df,\n",
    "  class_mode=\"binary\",\n",
    "  x_col=\"image\",\n",
    "  y_col=\"label\",\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed=42,\n",
    "  shuffle=True,\n",
    "  target_size=(IMG_HEIGHT,IMG_WIDTH) #set the height and width of the images\n",
    ")\n",
    "\n",
    "valDataset = valGenerator.flow_from_dataframe(\n",
    "  dataframe=val_df,\n",
    "  class_mode='binary',\n",
    "  x_col=\"image\",\n",
    "  y_col=\"label\",\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed=42,\n",
    "  shuffle=True,\n",
    "  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",
    ")\n",
    "\n",
    "testDataset = testGenerator.flow_from_dataframe(\n",
    "  dataframe=test_df,\n",
    "  class_mode='binary',\n",
    "  x_col=\"image\",\n",
    "  y_col=\"label\",\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed=42,\n",
    "  shuffle=True,\n",
    "  target_size=(IMG_HEIGHT,IMG_WIDTH)\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(testDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Batch shape: ', images.shape)\n",
    "print('Label shape: ', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[3])\n",
    "print('Label: ', labels[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=15\n",
    "\n",
    "#train the model\n",
    "history = model.fit(trainDataset, epochs=epochs, validation_data=(valDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualice the performance of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the model's training performance\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model on the test dataset\n",
    "loss, acc = model.evaluate(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss:', loss)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('pexels-cat-predict.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    img_resize = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    img_norm = img_resize / 255\n",
    "    return img_norm\n",
    "\n",
    "img = tf.reshape(img, (-1, IMG_HEIGHT, IMG_HEIGHT, 3))\n",
    "img = preprocess(img)\n",
    "model.predict(img)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.5 ('sentinel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1142c324dd5f12f780745ea69cec0a2edec4b8deec43df1726eba7f4fce95f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
